<div align="center">
    <h1>
        <b>Gesture Recognition</b>
    </h1>
    <h3>
        Сервис определения жестов рук на видеопотоке
    </h3>
    <img alt="GitHub Last Commit" src="https://img.shields.io/github/last-commit/alex6712/gesture-recognition?logo=GitHub">
    <img alt="Test and Deploy" src="https://github.com/alex6712/gesture-recognition/actions/workflows/test_and_deploy.yml/badge.svg">
    <a href="https://github.com/psf/black" style="font-size: 0;margin-right: 4px;">
        <img alt="Python code style: black" src="https://img.shields.io/badge/code%20style-black-000000.svg">
    </a>
    <a href="https://github.com/prettier/prettier">
        <img alt="TypeScript code style: Prettier" src="https://img.shields.io/badge/code%20style-prettier-ff69b4.svg">
    </a>
</div>

Код бакалаврской дипломной работы студента НГТУ им. Р.Е. Алексеева, Ванюкова Алексея Игоревича.

## Предисловие

Поступая в НГТУ я уже обладал некоторыми знаниями в IT. Я уже какое-то время программировал на **Python**,
знал **Java** и имел за спиной опыт нескольких простеньких проектов. Мне казалось, что я уже многое знаю.
Что ещё чуть-чуть — и я уже _молодой специалист_. Только через некоторое время я осознал, насколько я был далёк
от мира **_"настоящего" программирования_**.

Именно во время учёбы в университете, взаимодействуя с замечательным педагогическим составом,
я начал касаться этой необъятной области знаний. От семестра к семестру, от курса к курсу, предметы
становились всё более узкоспециализированными, задачи более интересными и разнообразными, а компетенции
неизбежно повышались.

И вот, пришло время выпуска. В данном проекте я, как студент-разработчик, хотел показать, чему я научился за время обучения
в университете:

- **_Веб-разработка_** - использование принципов _REST_, паттерны проектирования веб-приложений (_MVC_,
_Repository_ и др.), протоколы **HTTP/1.1** и **HTTP/2**;


- **_Машинное обучение_** - архитектуры нейросетей (_перцептроны_, _свёрточные_, _трансформеры_),
алгоритмы обучения (_NEAT_, _RL_ и др.), использование фреймворков (**PyTorch**, **TensorFlow**), оценка моделей;


- **_Работа с базами данных_** - язык **SQL**, реляционные базы данных (**PostgreSQL**, **SQLite**),
системы администрирования БД (**pgAdmin 4**, **DataGrip**), _ORM_ (**Spring JPA**, **SQLAlchemy**),
noSQL (**MongoDB**, **Redis**);


- **_Составление архитектуры приложения_** - подходы к проектированию приложений: _монолит_, _микросервисная архитектура_,
_гибридная архитектура_, - межсервисное взаимодействие (_gRPC_, _брокеры сообщений_), проектирование интерфейсов приложений;


- **_Составление документации_** - продвинутый технический английский язык, соблюдение терминологии, ведение
журнала разработчика, инструменты ведения документации приложения (**SwaggerUI**, **OpenAPI**, **NumPy Doc Style**,
**reStructuredText**);


- **_Тестирование и развёртка_** - классификация тестов (_юнит-тесты_, _интеграционные тесты_ и др.),
инструменты тестирования (**pytest**), _разработка через тестирование_, системы контейнеризации и оркестрации
(**Docker**, **Kubernetes**), веб-сервер **nginx**, CI/CD (**GitHub Action**, **Gitlab CI**, **Jenkins**);


- **_Администрирование серверов_** - **Linux**, операционные системы, файловые системы, сети и коммуникации, системы
реального времени, _SSH_.

Безусловно, многое мне ещё только предстоит узнать, а то что я уже знаю, предстоит углубить. Но эта выпускная
квалификационная работа является обобщением тех компетенций, что я получил, и должна стать первым уверенным шагом в
серьёзный **development**.

## Описание задачи

Общее описание выпускной квалификационной работы можно сформулировать таким образом:

<div align="center">
    <h3><b><i>Веб-приложение, предоставляющее возможность определения жестов, производимых руками и пальцами, на видеопотоке</i></b>.</h3>
</div>

Т.е. клиентское приложение захватывает видеопоток с доступного ему устройства и отправляет на сервер, где он обрабатывается моделью
компьютерного зрения. Ответом является один или несколько жестов, определённых моделью: их _вид_, _координаты_, _размеры_
и другая информация.

Данную задачу можно декомпозировать на 4 отдельные части:

### 1. Модель компьютерного зрения

Модель машинного обучения с использованием принципов компьютерного зрения, которая может определять
жесты человека на видеопотоке. Для обучения модели использовался набор данных [HaGRID](https://github.com/hukenovs/hagrid).

Основные использованные технологии и инструменты: **PyTorch**, **OpenCV**, **NumPy**.

### 2. RESTful API

API с использованием принципов REST для предоставления внешнего публичного интерфейса
к модели машинного обучения. Для соблюдения принципов микросервисной архитектуры *RESTful API*
и *модель* являются отдельными независимыми *сервисами*.

Основные использованные технологии и инструменты: **FastAPI**, **pydantic**.

### 3. Межсервисное взаимодействие через gRPC

Установка интерфейса общения между отдельными сервисами внутри приложения с использованием
**gRPC**. Клиентом выступает *сервис RESTful API*, сервером - *модель машинного обучения*.

Основные использованные технологии и инструменты: **gRPC**, **Protobuf**, **Bash**.

### 4. Развёртка приложения на удалённом сервере

Развёртка приложения на арендованном удалённом сервере с использованием систем контейнеризации
и средств *CI/CD*. Настройка веб-сервера, регистрация доменного имени, проброс прокси и администрирование
сервера. Настройка безопасного соединения по протоколу *HTTPS* используя сертификат *Let's Encrypt*.

Основные использованные технологии и инструменты: **GitHub Actions**, **Linux**, **Docker (docker-compose)**, **nginx**.

## Ссылка на приложение

### Веб-приложение

https://www.gesture-recognition-nntu.ru
или
https://gesture-recognition-nntu.ru

Готовое приложение, который реализует клиент-сервисное взаимодействие между устройством пользователя и сервером с моделью
компьютерного зрения. В качестве _frontend_-фреймворка использовался **Angular**.

### Сервис _RESTful API_

https://api.gesture-recognition-nntu.ru

Модель компьютерного зрения открыта к использованию через **API Gateway**.
Информацию о лицензии см. в блоке [Лицензия](https://github.com/alex6712/gesture-recognition?tab=readme-ov-file#лицензия).

Документация _API_: https://api.gesture-recognition-nntu.ru/docs

## Примеры

Примеры запросов на различные _endpoints_.

### *root*

Запрос **curl**:
```
curl -X 'GET' \
  'https://api.gesture-recognition-nntu.ru/api/v1/' \
  -H 'accept: application/json'
```

**Request URL**:
```
https://api.gesture-recognition-nntu.ru/api/v1/
```

Ответ **StandardResponse**:
```json
{
  "code": 200,
  "message": "API works!"
}
```

## Лицензия

Данный проект находится под лицензией [MIT License/X11 License](https://github.com/alex6712/gesture-recognition/blob/master/LICENSE).

## Автор

Ванюков Алексей Игоревич, НГТУ, ИРИТ, группа 21-ИС, 2025 год.

Контакты:
- Telegram: [@ecuripusu](https://t.me/ecuripusu)
- ВКонтакте: [Ванюков Алексей](https://vk.com/zerolevelmath)
- Адрес электронной почты: alexeivanyukov@yandex.ru
